{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyPhbOdXckyU3UC0U9Cp1Bzu"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Ymt4YKZVrMG-"},"outputs":[],"source":["!pip install git+https://github.com/huggingface/transformers.git\n","!pip install datasets\n","!pip install transformers torch\n","!pip install accelerate\n","!apt install git-lfs"]},{"cell_type":"code","source":["from huggingface_hub import notebook_login\n","notebook_login()"],"metadata":{"id":"hMdf-byisQa6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import os\n","os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n","torch.cuda.empty_cache()\n","\n","from typing import Dict, Tuple\n","from datasets import list_datasets, load_dataset, DatasetDict,Dataset\n","from collections import Counter\n","from typing import List, Dict, Union, Callable, Any\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import seaborn as sns\n","from pprint import pprint\n","import torch\n","import torch.nn as nn"],"metadata":{"id":"Kgrt0lv4rZqa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","print(device)    "],"metadata":{"id":"hf2s_MJdrceK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train = load_dataset(\"Sree1994/babylm_100M\", split=\"train\")\n","traindata = train[\"text\"]\n","traindata[:10]"],"metadata":{"id":"eH-8L4s8riaF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["all_tokens=[]\n","for line in traindata:\n","  lst=line.split()\n","  all_tokens.extend(lst)"],"metadata":{"id":"IePi25qSt2db"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(all_tokens)\n","len(set(all_tokens))"],"metadata":{"id":"kjfgKLl8uNmN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tqdm import tqdm\n","from transformers import RobertaTokenizer\n","\n","# repositor id for saving the tokenizer\n","tokenizer_id=\"roberta-base-BabyLM\"\n","\n","# create a python generator to dynamically load the data\n","def batch_iterator(batch_size=10000):\n","    for i in tqdm(range(0, len(traindata), batch_size)):\n","        yield traindata[i : i + batch_size][\"text\"]\n","\n","# create a tokenizer from existing one to re-use special tokens\n","tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")"],"metadata":{"id":"thvXtlc-sCSe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["roberta_tknzr = tokenizer.train_new_from_iterator(text_iterator=batch_iterator(), vocab_size=32_000)\n","roberta_tknzr.save_pretrained(\"tokenizer\")\n","# # you need to be logged into push the tokenizer\n","# roberta_tknzr.push_to_hub(tokenizer_id)\n","tokenizer."],"metadata":{"id":"y1z4XTIAtZw3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dir(tokenizer)"],"metadata":{"id":"FAnTnn9uu7I-"},"execution_count":null,"outputs":[]}]}